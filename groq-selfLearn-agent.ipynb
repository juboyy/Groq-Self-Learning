{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juboyy/Groq-Self-Learning/blob/main/groq-selfLearn-agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zwFnJsE6vjf8",
        "outputId": "c422df29-d3e3-4592-d945-d9ef997241cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/318.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, python-dotenv, orjson, mypy-extensions, marshmallow, jsonpointer, jiter, h11, typing-inspect, tiktoken, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, openai, langsmith, groq, langchain_core, langchain-text-splitters, langchain_openai, langchain-groq, langchain, langchain_community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.1 langchain-groq-0.2.0 langchain-text-splitters-0.3.0 langchain_community-0.3.1 langchain_core-0.3.6 langchain_openai-0.2.1 langsmith-0.1.128 marshmallow-3.22.0 mypy-extensions-1.0.0 openai-1.48.0 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai langchain-groq langchain_core python-dotenv langchain langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "ppOubv57fV-j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vamos definir funções de apoio para cada habilidade do nosso agente**"
      ],
      "metadata": {
        "id": "OMzaZih3f6sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerenciamento de Histórico do chat (Chat History Mngmt.)\n",
        "\n",
        "def get_chat_history(store, session_id: str):\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "f6NvTnAXgC1v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar Resposta\n",
        "\n",
        "def generate_response(chain_with_history, human_input: str, session_id: str, insights: str):\n",
        "    response = chain_with_history.invoke(\n",
        "        {\"input\": human_input, \"insights\": insights},\n",
        "        config={\"configurable\": {\"session_id\": session_id}}\n",
        "    )\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "Ag9FZbyKgepp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reflexão\n",
        "def reflect(llm, store, session_id: str):\n",
        "    reflection_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Based on the following conversation history, provide insights on how to improve responses:\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"Generate insights for improvement:\")\n",
        "    ])\n",
        "    reflection_chain = reflection_prompt | llm\n",
        "    history = get_chat_history(store, session_id)\n",
        "    reflection_response = reflection_chain.invoke({\"history\": history.messages})\n",
        "    return reflection_response.content"
      ],
      "metadata": {
        "id": "PjhVSc-ngt7X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aprendizado\n",
        "def learn(llm, store, session_id: str, insights: str):\n",
        "    learning_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Based on these insights, update the agent's knowledge and behavior:\"),\n",
        "        (\"human\", \"{insights}\"),\n",
        "        (\"human\", \"Summarize the key points to remember:\")\n",
        "    ])\n",
        "    learning_chain = learning_prompt | llm\n",
        "    learned_points = learning_chain.invoke({\"insights\": insights}).content\n",
        "    get_chat_history(store, session_id).add_ai_message(f\"[SYSTEM] Agent learned: {learned_points}\")\n",
        "    return learned_points"
      ],
      "metadata": {
        "id": "Efpsb3X_hBKs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-Improving Agent Class\n",
        "# vamos definir nossa classe de agente que utiliza todas estas funções acima\n",
        "\n",
        "class SelfImprovingAgent:\n",
        "    def __init__(self):\n",
        "        self.llm = ChatGroq(model=\"llama3-groq-70b-8192-tool-use-preview\", max_tokens=1000, temperature=0.7)\n",
        "        self.store = {}\n",
        "        self.insights = \"\"\n",
        "\n",
        "        self.prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are a self-improving AI assistant. Learn from your interactions and improve your performance over time. apenas responda em pt-br\"),\n",
        "            MessagesPlaceholder(variable_name=\"history\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            (\"system\", \"Recent insights for improvement: {insights}\")\n",
        "        ])\n",
        "\n",
        "        self.chain = self.prompt | self.llm\n",
        "        self.chain_with_history = RunnableWithMessageHistory(\n",
        "            self.chain,\n",
        "            lambda session_id: get_chat_history(self.store, session_id),\n",
        "            input_messages_key=\"input\",\n",
        "            history_messages_key=\"history\"\n",
        "        )\n",
        "\n",
        "    def respond(self, human_input: str, session_id: str):\n",
        "        return generate_response(self.chain_with_history, human_input, session_id, self.insights)\n",
        "\n",
        "    def reflect(self, session_id: str):\n",
        "        self.insights = reflect(self.llm, self.store, session_id)\n",
        "        return self.insights\n",
        "\n",
        "    def learn(self, session_id: str):\n",
        "        self.reflect(session_id)\n",
        "        return learn(self.llm, self.store, session_id, self.insights)\n"
      ],
      "metadata": {
        "id": "VTAQmajNhEj_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = SelfImprovingAgent()\n",
        "session_id = \"user_123\"\n",
        "\n",
        "\n",
        "# Interaction 1\n",
        "print(\"AI:\", agent.respond(\"What's the capital of Brazil?\", session_id))\n",
        "\n",
        "# Interaction 2\n",
        "print(\"AI:\", agent.respond(\"Can you tell me more about its history?\", session_id))\n",
        "\n",
        "# Learn and improve\n",
        "print(\"\\nReflecting and learning...\")\n",
        "learned = agent.learn(session_id)\n",
        "print(\"Learned:\", learned)\n",
        "\n",
        "# Interaction 3 (potentially improved based on learning)\n",
        "print(\"\\nAI:\", agent.respond(\"What's a famous landmark in this city?\", session_id))\n",
        "\n",
        "# Interaction 4 (to demonstrate continued improvement)\n",
        "print(\"AI:\", agent.respond(\"What's another interesting fact about this city?\", session_id))\n"
      ],
      "metadata": {
        "id": "-wfFSUaDhm7i",
        "outputId": "2e17e1a4-904b-44f7-876c-979687026a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: A capital do Brasil é Brasília.\n",
            "AI: Brasília é a capital do Brasil desde 1960. Foi projetada pelo arquiteto Oscar Niemeyer e inaugurada em 21 de abril de 1960. A cidade é conhecida por seus edifícios modernistas e é considerada um exemplo de arquitetura moderna.\n",
            "\n",
            "Reflecting and learning...\n",
            "Learned: 1. Provide more detailed information about the capital's history and significance.\n",
            "2. Include interesting facts or anecdotes about the capital.\n",
            "3. Use a more conversational tone in responses.\n",
            "4. Encourage follow-up questions by ending with a question or prompt.\n",
            "\n",
            "AI: Um dos mais famosos marcos de Brasília é a Catedral Metropolitana, projetada por Oscar Niemeyer. Ela é conhecida por sua arquitetura moderna e seus 16 pilares de concreto que sustentam a estrutura. A catedral é considerada um dos principais pontos turísticos da cidade.\n",
            "AI: Uma outra coisa interessante sobre Brasília é que a cidade foi construída do zero em uma área remota do país. Isso fez com que a cidade fosse declarada Patrimônio Mundial da UNESCO em 1987. Além disso, a cidade é planejada de forma que as ruas sejam projetadas como asas de um avião, o que a torna única em termos de urbanismo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fDyP0SKaho78"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Olá, este é o Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}